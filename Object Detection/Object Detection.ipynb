{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd28d815",
   "metadata": {},
   "source": [
    "# Object Detection Using Jetson Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbf87bb",
   "metadata": {},
   "source": [
    "The following module translates the team's efforts to detect objects using the jetson inference module provided by Nvidia in their \"Hello AI World\" series of open source online courses. It assumes that pytorch and torchvision has been installed to the OS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c48739",
   "metadata": {},
   "source": [
    "## Setting Up The Camera "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311efa50",
   "metadata": {},
   "source": [
    "To make sure, that your CSI camera works correctly; ssh into your jetson nano or open a terminal in your wire connected desktop and run the following command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7047dfe",
   "metadata": {},
   "source": [
    "`nvgstcapture-1.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c4f099",
   "metadata": {},
   "source": [
    "If you can see a live camera feed, this means that the CSI camera was setup correctly and is now ready for further use. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c99fcb",
   "metadata": {},
   "source": [
    "#### Common Mistakes and How To Fix Them:\n",
    "\n",
    "1) No feed is seen on the monitor: Make sure that the tail of the CSI camera is properly connected to the jetson board. Use screws to tighten the pocket on the board if needed.\n",
    "\n",
    "2) Error with GStreamer/Image Buffer: The GStreamer pipelines you are using arenÂ´t exactly the same, they differ in the caps and elements used. For example, framerate and resolution are different.You may try the following GStreamer pipeline (based on your opencv snippet) with gst-launch-1.0 to check if it runs: \n",
    "`gst-launch-1.0 -v nvarguscamerasrc ! 'video/x-raw(memory:NVMM),width=1280, height=720, framerate=60/1, format=NV12' ! nvvidconv flip-method=0 ! 'video/x-raw, width=1280, height=720, format=BGRx' ! videoconvert ! 'video/x-raw, format=BGR' ! identity silent=false ! fakesink -e`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfe43ff",
   "metadata": {},
   "source": [
    "## Setting Up Jetson Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4046de8d",
   "metadata": {},
   "source": [
    "Follow the followig instructions to successfully setup the jetson inference module and its dependencies on your OS. This will be used in all the tasks that would be done after. Reference: [Building Project from Source](https://github.com/dusty-nv/jetson-inference/blob/master/docs/building-repo-2.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9e0e29",
   "metadata": {},
   "source": [
    "`$ sudo apt-get update\n",
    "$ sudo apt-get install git cmake libpython3-dev python3-numpy\n",
    "$ git clone --recursive https://github.com/dusty-nv/jetson-inference\n",
    "$ cd jetson-inference\n",
    "$ mkdir build\n",
    "$ cd build\n",
    "$ cmake ../\n",
    "$ make -j$(nproc)\n",
    "$ sudo make install\n",
    "$ sudo ldconfig\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d781a3",
   "metadata": {},
   "source": [
    "By running the above commands, you have now successfully cloned the repo, built, configured and complied the project from the cmake file and downloaded the necessary models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf5771a",
   "metadata": {},
   "source": [
    "#### Common Mistakes and How To Fix Them:\n",
    "1) Cmake was not installed: Make sure that the cmake has been preinstalled. Use `cmake --version` to confirm and if need be run `sudo pip install cmake` to install cmake.\n",
    "\n",
    "2) Not all models were downloaded: When the below pop up box shows up, make sure that you download all the models and not just a selected few. All of these models would be required for the DetectNet object detection model that we will be using in this task.\n",
    "<img src= \"download-models.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e451e77b",
   "metadata": {},
   "source": [
    "## Collecting your Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eb560c",
   "metadata": {},
   "source": [
    "Assuming that your camera has been setup correctly and a live feed from the camera is now accessible, we are now free to collect our custom dataset for the object detection. To collect the images with the bounding boxes for detection, we will be using NVidia's pre built dialog box that can be triggered using the `camera-capture` feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eac555",
   "metadata": {},
   "source": [
    "Navigate to the ssd folder: `cd jetson-inference/python/training/detection/ssd`\n",
    "\n",
    "Run the camera capture feature: `camera-capture csi://0`\n",
    "\n",
    "The below pop up box opens on the desktop:\n",
    "<img src= \"pytorch-collection-detection-widget.jpg\">\n",
    "\n",
    "You should now set the dataset path of the annotations folder you would like to store the annotated images in.\n",
    "\n",
    "You should now create a .txt file called \"labels.txt\" in the above folder and write (on different lines) the names of the objects to be detected. Set the labels path to the labels.txt file\n",
    "\n",
    "You must set the Dataset Type to Detection.\n",
    "\n",
    "You can toggle between train and test as the Current Set depending on your requirement for quantity of data for your model's training and testing.\n",
    "\n",
    "To make saving simpler, select the tick box named \"Save on Unfreeze\" and clear the tick box named \"Clear on Unfreeze\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d3fee7",
   "metadata": {},
   "source": [
    "### Marking your Images\n",
    "\n",
    "Bring the objects to be annotated closer to the camera and click on `Freeze/Edit (space)`. Draw a bounding box around the object and select the class of the object.\n",
    "\n",
    "Click on the `Freeze/Edit (space)` button again. Your annotated image has now been saved in the dataset path folder. \n",
    "\n",
    "You can view the images by navigating to the folder. The images are stored in the Annotations folder inside the dataset folder.\n",
    "\n",
    "The tool uses Pascal VOC format for storing data which is also the format that our model requires.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb0e2fd",
   "metadata": {},
   "source": [
    "#### Common Mistakes and How To Fix Them:\n",
    "1) Issue with gstreamer while running camera-capture: Navigate to the ssd folder and try running the command `camera-capture csi://0 --input-flip=rotate-180` \n",
    "\n",
    "2) Bounding boxes are loose: Try drawing the bboxes as compact as possible for better accuracy of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd634cd4",
   "metadata": {},
   "source": [
    "## Training Your Model on Your Newly Collected DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ff7cdc",
   "metadata": {},
   "source": [
    "We will be training a new model using the `train_ssd.py` file after which the model would be loaded on to [DetectNet](https://github.com/dusty-nv/jetson-inference/blob/master/docs/pytorch-ssd.md) which employs CNN to detect object and non-maximal suppression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb628d",
   "metadata": {},
   "source": [
    "To train your model cd into your ssd folder and run the command `python3 train_ssd.py --dataset-type=voc --data=data/<YOUR-DATASET> --model-dir=models/<YOUR-MODEL>` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a69eefb",
   "metadata": {},
   "source": [
    "After training you'll need to convert your PyTorch model to ONNX:\n",
    "`python3 onnx_export.py --model-dir=models/<YOUR-MODEL>`\n",
    "The converted model will then be saved under `<YOUR-MODEL>/ssd-mobilenet.onnx`, which you can then load with the detectnet program:\n",
    "\n",
    "`NET=models/<YOUR-MODEL>`\n",
    "\n",
    "`detectnet --model=$NET/ssd-mobilenet.onnx --labels=$NET/labels.txt \\\n",
    "          --input-blob=input_0 --output-cvg=scores --output-bbox=boxes \\\n",
    "            csi://0\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed438e5",
   "metadata": {},
   "source": [
    "You can now detect the objects by using the live camera feed and the accuracy is shown on the edge of the box."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
